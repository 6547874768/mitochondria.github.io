#!/usr/bin/env python3
import os
import re
from datetime import datetime
from pathlib import Path
import xml.etree.ElementTree as ET
from xml.dom import minidom

def get_article_info(folder_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ HTML —Ñ–∞–π–ª–∞"""
    index_file = os.path.join(folder_path, 'index.html')
    
    if not os.path.exists(index_file):
        return None
    
    try:
        with open(index_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º title
        title_match = re.search(r'<title>(.*?)</title>', content, re.IGNORECASE)
        title = title_match.group(1) if title_match else folder_path
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º meta description
        desc_match = re.search(r'<meta name="description" content="(.*?)"', content, re.IGNORECASE)
        description = desc_match.group(1) if desc_match else title
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏–∑ schema.org
        date_match = re.search(r'"datePublished":\s*"(.*?)"', content)
        if date_match:
            pub_date = date_match.group(1)
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞—Ç—É –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            timestamp = os.path.getmtime(index_file)
            pub_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%dT%H:%M:%SZ')
        
        return {
            'title': title,
            'description': description,
            'link': f"https://www.danilichev.info/{folder_path}/",
            'guid': f"https://www.danilichev.info/{folder_path}/",
            'pubDate': pub_date,
            'folder': folder_path
        }
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {folder_path}: {e}")
        return None

def create_rss_feed():
    """–°–æ–∑–¥–∞–µ—Ç RSS feed –∏–∑ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π"""
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–∞–ø–æ–∫
    folders = []
    for item in os.listdir('.'):
        if os.path.isdir(item) and not item.startswith('.') and not item.startswith('_'):
            # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–∞–ø–∫–∏
            if item not in ['images', 'css', 'js', 'fonts']:
                folders.append(item)
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å—è—Ö
    articles = []
    for folder in folders:
        info = get_article_info(folder)
        if info:
            articles.append(info)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    articles.sort(key=lambda x: x['pubDate'], reverse=True)
    
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å—Ç–∞—Ç–µ–π
    articles = articles[:50]
    
    # –°–æ–∑–¥–∞–µ–º RSS —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    rss = ET.Element('rss', version='2.0')
    channel = ET.SubElement(rss, 'channel')
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–Ω–∞–ª–µ
    ET.SubElement(channel, 'title').text = 'Danilichev Health Blog'
    ET.SubElement(channel, 'link').text = 'https://www.danilichev.info/'
    ET.SubElement(channel, 'description').text = 'Evidence-based dental health research and natural supplement optimization'
    ET.SubElement(channel, 'language').text = 'en-us'
    ET.SubElement(channel, 'lastBuildDate').text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—å–∏
    for article in articles:
        item = ET.SubElement(channel, 'item')
        ET.SubElement(item, 'title').text = article['title']
        ET.SubElement(item, 'link').text = article['link']
        ET.SubElement(item, 'description').text = article['description']
        ET.SubElement(item, 'guid').text = article['guid']
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –¥–ª—è RSS
        try:
            dt = datetime.fromisoformat(article['pubDate'].replace('Z', '+00:00'))
            pub_date_rss = dt.strftime('%a, %d %b %Y %H:%M:%S GMT')
        except:
            pub_date_rss = datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')
        
        ET.SubElement(item, 'pubDate').text = pub_date_rss
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∫—Ä–∞—Å–∏–≤—ã–π XML
    xml_str = ET.tostring(rss, encoding='unicode')
    dom = minidom.parseString(xml_str)
    pretty_xml = dom.toprettyxml(indent="  ")
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω—é—é –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É XML declaration
    lines = pretty_xml.split('\n')
    pretty_xml = '<?xml version="1.0" encoding="UTF-8"?>\n' + '\n'.join(lines[1:])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    with open('feed.xml', 'w', encoding='utf-8') as f:
        f.write(pretty_xml)
    
    print(f"‚úÖ RSS feed —Å–æ–∑–¥–∞–Ω: {len(articles)} —Å—Ç–∞—Ç–µ–π –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ feed.xml")

if __name__ == "__main__":
    create_rss_feed()
    print("üéâ RSS feed —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω!")
