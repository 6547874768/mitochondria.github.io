import os
import datetime
import re

SITE_URL = "https://www.danilichev.info"

FAVICON_HTML = '''    <!-- Favicon -->
<link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/svg+xml" href="/favicon.svg" />
<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
<meta name="apple-mobile-web-app-title" content="Health Supplements Hub" />
<link rel="manifest" href="/site.webmanifest" />'''

def get_page_title(file_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç title –∏–∑ HTML —Ñ–∞–π–ª–∞"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ò—â–µ–º <title>...</title>
        title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE | re.DOTALL)
        if title_match:
            title = title_match.group(1).strip()
            # –£–±–∏—Ä–∞–µ–º –æ–±—â—É—é —á–∞—Å—Ç—å —Å–∞–π—Ç–∞ –∏–∑ title
            title = re.sub(r'\s*-\s*Health Supplements Hub.*$', '', title)
            title = re.sub(r'\s*\|\s*Health Supplements Hub.*$', '', title)
            return title[:60]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        
        # –ï—Å–ª–∏ title –Ω–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –∏–∑ h1
        h1_match = re.search(r'<h1[^>]*>(.*?)</h1>', content, re.IGNORECASE | re.DOTALL)
        if h1_match:
            h1_text = re.sub(r'<[^>]+>', '', h1_match.group(1)).strip()
            return h1_text[:60]
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ—Ç, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑ URL
        dir_name = os.path.basename(os.path.dirname(file_path))
        return dir_name.replace('-', ' ').title()
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è title –∏–∑ {file_path}: {e}")
        return "Unknown Page"

def scan_content_pages():
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –ø–∞–ø–∫–∞—Ö (–∏—Å–∫–ª—é—á–∞–µ—Ç .html —Ñ–∞–π–ª—ã)"""
    
    # –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ –ø–∞–ø–∫–∏ (–≥–ª–∞–≤–Ω–∞—è + 5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
    excluded_dirs = {
        'health-supplements', 'health-products', 'anti-aging-hacks', 
        'brain-supplements', 'weight-loss-supplements'
    }
    
    content_pages = []
    
    # –¢–û–õ–¨–ö–û –ø–∞–ø–∫–∏ —Å index.html (—Å—Ç–∞—Ç—å–∏ —Å–æ —Å–ª–µ—à–µ–º /)
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        
        if root == '.':
            continue
            
        dir_name = os.path.basename(root)
        if dir_name in excluded_dirs:
            continue
            
        if 'index.html' in files:
            file_path = os.path.join(root, 'index.html')
            url_path = '/' + os.path.relpath(root, '.').replace('\\', '/') + '/'
            title = get_page_title(file_path)
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            mod_time = os.path.getmtime(file_path)
            mod_date = datetime.datetime.fromtimestamp(mod_time)
            
            content_pages.append({
                'url': url_path,
                'title': title,
                'file_path': file_path,
                'mod_date': mod_date
            })
            print(f"üìÑ –ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: {url_path} - {title}")
    
    # –ù–ï —Å–∫–∞–Ω–∏—Ä—É–µ–º .html —Ñ–∞–π–ª—ã - —ç—Ç–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
    content_pages.sort(key=lambda x: x['mod_date'], reverse=True)
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(content_pages)} –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (—Ç–æ–ª—å–∫–æ –ø–∞–ø–∫–∏ —Å–æ —Å–ª–µ—à–µ–º)")
    return content_pages

def update_footer_component():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç footer-component.js —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º —Å–ø–∏—Å–∫–æ–º —Å—Ç–∞—Ç–µ–π"""
    
    content_pages = scan_content_pages()
    
    # –ë–µ—Ä–µ–º —Ç–æ–ø-10 —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è —Ñ—É—Ç–µ—Ä–∞
    popular_articles = content_pages[:10]
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
    popular_html = ""
    for page in popular_articles:
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        title = page['title']
        if 'mitochondrial' in title.lower() and 'formula' in title.lower():
            title = f"üöÄ {title}"
        elif any(word in title.lower() for word in ['tired', 'fatigue', 'energy']):
            title = f"‚ö° {title}"
        elif 'brain' in title.lower():
            title = f"üß† {title}"
        elif 'nad' in title.lower():
            title = f"üî¨ {title}"
            
        popular_html += f'                    <li><a href="{page["url"]}">{title}</a></li>\n'
    
    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π footer-component.js
    footer_file = 'footer-component.js'
    
    try:
        with open(footer_file, 'r', encoding='utf-8') as f:
            footer_content = f.read()
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {footer_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return False
    
    # –ù–∞—Ö–æ–¥–∏–º —Å–µ–∫—Ü–∏—é "Popular Articles" –∏ –∑–∞–º–µ–Ω—è–µ–º –µ—ë
    pattern = r'(<h3>üî• Popular Articles</h3>\s*<ul>\s*)(.*?)(\s*</ul>)'
    
    new_popular_section = f'\\g<1>{popular_html.rstrip()}\\g<3>'
    
    new_footer_content = re.sub(pattern, new_popular_section, footer_content, flags=re.DOTALL)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–º–µ–Ω–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞
    if new_footer_content == footer_content:
        print("‚ö†Ô∏è –°–µ–∫—Ü–∏—è Popular Articles –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å")
        return False
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    with open(footer_file, 'w', encoding='utf-8') as f:
        f.write(new_footer_content)
    
    print(f"‚úÖ Footer –æ–±–Ω–æ–≤–ª–µ–Ω! –î–æ–±–∞–≤–ª–µ–Ω–æ {len(popular_articles)} –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
    
    # –í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
    print("üìã –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π:")
    for i, page in enumerate(popular_articles, 1):
        print(f"   {i}. {page['title']} ‚Üí {page['url']}")
    
    return True

def generate_sitemap():
    today = datetime.date.today().strftime('%Y-%m-%d')
    
    # –°–¢–ê–¢–ò–ß–ï–°–ö–ò–ï –°–¢–†–ê–ù–ò–¶–´ –° –ü–†–ê–í–ò–õ–¨–ù–´–ú–ò –ü–†–ò–û–†–ò–¢–ï–¢–ê–ú–ò
    pages = [
        # Main Homepage
        {'url': '/', 'priority': '1.0', 'changefreq': 'weekly'},
        
        # Product Landing Page
        {'url': '/advanced-mitochondrial-formula/', 'priority': '0.95', 'changefreq': 'monthly'},
        
        # Category Pages
        {'url': '/health-supplements/', 'priority': '0.9', 'changefreq': 'weekly'},
        {'url': '/health-products/', 'priority': '0.9', 'changefreq': 'weekly'},
        {'url': '/anti-aging-hacks/', 'priority': '0.9', 'changefreq': 'weekly'},
        {'url': '/brain-supplements/', 'priority': '0.9', 'changefreq': 'weekly'},
        {'url': '/weight-loss-supplements/', 'priority': '0.9', 'changefreq': 'weekly'},
    ]
    
    # AUTO-DETECTION –¥–ª—è –Ω–æ–≤—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    print("üîç Scanning for new pages...")
    
    # 1. –ü–æ–∏—Å–∫ –ø–∞–ø–æ–∫ —Å index.html
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        if root == '.':
            continue
        
        if 'index.html' in files:
            dir_path = os.path.relpath(root, '.')
            url_path = '/' + dir_path.replace('\\', '/') + '/'
            
            if not any(page['url'] == url_path for page in pages):
                print(f"üìÑ New page found (folder): {url_path}")
                pages.append({
                    'url': url_path,
                    'priority': '0.8',
                    'changefreq': 'monthly'
                })
    
    # 2. –ü–æ–∏—Å–∫ .html —Ñ–∞–π–ª–æ–≤ –≤ –∫–æ—Ä–Ω–µ (–∫—Ä–æ–º–µ index.html –∏ 404.html)
    for file in os.listdir('.'):
        if file.endswith('.html') and file not in ['index.html', '404.html']:
            url_path = '/' + file
            
            if not any(page['url'] == url_path for page in pages):
                print(f"üìÑ New page found (HTML file): {url_path}")
                # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 0.7, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - 0.8
                priority = '0.7' if file in [
                    'affiliate-disclosure.html', 'contact-us.html', 'disclaimer.html',
                    'editorial-policy.html', 'privacy-policy.html', 'terms-of-use.html',
                    'sitemap.html', 'about-us.html'
                ] else '0.8'
                
                pages.append({
                    'url': url_path,
                    'priority': priority,
                    'changefreq': 'monthly'
                })
    
    # GENERATE XML
    xml_content = '''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9
        http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd">

    <!-- Main Homepage -->'''
    
    # Sort by priority (highest first)
    pages_sorted = sorted(pages, key=lambda x: float(x['priority']), reverse=True)
    
    current_priority = None
    for page in pages_sorted:
        full_url = SITE_URL + page['url']
        
        # Add section comments
        if current_priority != page['priority']:
            current_priority = page['priority']
            if page['priority'] == '0.95':
                xml_content += '\n\n    <!-- Product Landing Page -->'
            elif page['priority'] == '0.9':
                xml_content += '\n\n    <!-- Category Pages -->'
            elif page['priority'] == '0.8':
                xml_content += '\n\n    <!-- Content Articles -->'
            elif page['priority'] == '0.7':
                xml_content += '\n\n    <!-- CRITICAL TECHNICAL PAGES for YMYL compliance -->'
            elif page['priority'] == '0.6':
                xml_content += '\n\n    <!-- Site Navigation -->'
        
        xml_content += f'''
    <url>
        <loc>{full_url}</loc>
        <lastmod>{today}</lastmod>
        <changefreq>{page['changefreq']}</changefreq>
        <priority>{page['priority']}</priority>
    </url>'''
    
    xml_content += '''

</urlset>'''
    
    with open('sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(xml_content)
    
    print(f"‚úÖ Sitemap updated with {len(pages)} pages")
    
    # Count by type
    technical_pages = [p for p in pages if p['priority'] == '0.7']
    content_pages = [p for p in pages if p['priority'] == '0.8']
    print(f"üìä Technical pages: {len(technical_pages)}")
    print(f"üìä Content pages: {len(content_pages)}")
    print(f"üìä Total pages: {len(pages)}")

def check_and_add_favicon():
    updated_files = []
    
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        
        for file in files:
            if file.endswith('.html'):
                file_path = os.path.join(root, file)
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if 'favicon' in content.lower() or 'apple-touch-icon' in content.lower():
                        continue
                    
                    if '</head>' not in content:
                        continue
                    
                    new_content = content.replace('</head>', f'{FAVICON_HTML}\n</head>')
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    
                    updated_files.append(file_path)
                    print(f"Favicon added to: {file_path}")
                    
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
    
    if updated_files:
        print(f"Favicon added to {len(updated_files)} files")
    else:
        print("All files already have favicon")

def add_footer_to_content_pages():
    """Add footer component to content pages (exclude main + 5 categories)"""
    
    # Pages WITHOUT footer (main + 5 categories)
    excluded_pages = {
        './index.html',
        './health-supplements/index.html',
        './health-products/index.html', 
        './anti-aging-hacks/index.html',
        './brain-supplements/index.html',
        './weight-loss-supplements/index.html',
        './404.html'
    }
    
    footer_script = '<script src="/footer-component.js"></script>'
    updated_files = []
    
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        
        for file in files:
            if file.endswith('.html'):
                file_path = os.path.join(root, file).replace('\\', '/')
                normalized_path = './' + file_path if not file_path.startswith('./') else file_path
                
                # Skip excluded pages
                if normalized_path in excluded_pages:
                    print(f"‚è≠Ô∏è Skipping: {file_path} (excluded)")
                    continue
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Check if footer already exists
                    if 'footer-component.js' in content:
                        print(f"‚úÖ Footer already exists: {file_path}")
                        continue
                    
                    # Check if </body> exists
                    if '</body>' not in content:
                        print(f"‚ö†Ô∏è No </body> found in: {file_path}")
                        continue
                    
                    # Add footer script before </body>
                    new_content = content.replace('</body>', f'{footer_script}\n</body>')
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    
                    updated_files.append(file_path)
                    print(f"‚ûï Footer added to: {file_path}")
                    
                except Exception as e:
                    print(f"‚ùå Error processing {file_path}: {e}")
    
    if updated_files:
        print(f"ü¶∂ Footer added to {len(updated_files)} content pages")
    else:
        print("ü¶∂ All content pages already have footer")

def main():
    print("üöÄ Starting site update...")
    print("=" * 50)
    
    print("\n1Ô∏è‚É£ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ—É—Ç–µ—Ä–∞...")
    update_footer_component()
    
    print("\n2Ô∏è‚É£ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è sitemap...")
    generate_sitemap()
    
    print("\n3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ favicon...")
    check_and_add_favicon()
    
    print("\n4Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ—É—Ç–µ—Ä–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
    add_footer_to_content_pages()
    
    print("\n" + "=" * 50)
    print("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∞–π—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("üéØ –§—É—Ç–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ —Å—Ç–∞—Ç—å—è–º–∏")

if __name__ == "__main__":
    main()
